---
title: Interpretations of the Fourier Transform, Part 2
date: "2019-08-08T22:40:32.169Z"
template: "post"
draft: false
slug: "/posts/interpretations-of-the-fourier-transform-part-2/"
category: "Signal Processing"
tags:
  - "Signal Processing"
  - "Math"
description: "As a projection of eigenfunctions"
---

## Background on Vectors and Subspaces

Vectorizing signals provides an alternative lens by which to view the Fourier Transform. You may be familiar with the 3-dimensional Euclidian space $\mathbb{R}^3$, composed of the orthogonal basis functions $i$, $j$, and $k$. The term "orthogonal" is defined in terms of the inner product of this space, which is the familiar dot product:
$$
\langle x, y \rangle = x \cdot y = x_1y_1 + x_2y_2 + x_3y_3.
$$
In general, two vectors are orthogonal if the inner product between the two vectors is $0$,
$$
\langle x, y \rangle = 0
$$
The orthogonality of these basis functions is important; it's what allows us to express any vector that lives in this space as a weighted linear sum of these basis functions:
$$
v = v_1 i + v_2 j + v_3 k.
$$
If two vectors are orthogonal, you may think intuitively that there is no information of one vector in the "direction" of the other vector. Furthermore, decomposing a space into its basis functions completely "characterizes" the degrees of freedom inherent in that space. That is, the basis functions are the most elemental vectors within that space by which all other vectors can be built. Indeed, having one less basis function would render you unable to express a whole host of vectors (e.g. we would only be able to express 2D vectors), and having one more basis vector would be redundant (why have one more when 3 is perfectly enough).

If an inner product of $0$ between two vectors implies no mutual information in the direction of the vectors, you may surmise that a non-zero value of the inner product leads to some notion of "overlap" or "projection" between the two vectors. Indeed, we may find the projection of one vector $x$ in the direction of the other vector $y$ $proj_y : \mathbb{R}^n \rightarrow \mathbb{R}$ as proportional to the inner product of the two vectors:
$$
proj_y(x) = \frac{\langle x, y \rangle}{||y||}.
$$
The denominator $\langle y, y \rangle$ is a normalizing factor that allows projection of $x$ onto a normalized unit vector $\hat{y} = \frac{y}{\langle y, y \rangle}$. 

## Aside: Some properties of the vector space of functions
Now, I will outline some properties of the vector space of functions that we will need later.
Let $S$ be defined as the space of square-integrable functions:
$$
S = \{x(t) : \int_{\mathbb{R}} |x(t)|^2 dt < \infty\}.
$$
+ S has the inner product
$$
\langle x, y \rangle = \int_{-\infty}^\infty x(t) y^*(t) dt,
$$
where $^*$ denotes the complex conjugate.
+ The space of complex exponentials $\{e^{j \omega t}\}_{\omega=-\infty}^\infty$ is a basis for $S$.[^1] 

## Putting it all together
Here's an alternative view of the Fourier transform:
> The Fourier transform $F(\omega)$ is the scalar projection onto the subspace generated by a complex exponential of frequency $\omega$, for all $\omega \in \mathbb{R}$.

In other words, instead of looking at a signal as some quantity (e.g. voltage, current, etc.) that is changing over time, we will look at it as some quantity that is changing over frequency. For each particular frequency $\omega$, we will project our signal onto the subspace generated by that frequency, and the function that represents all these projections over any frequency $\omega$ is the Fourier transform, $F(\omega)$!

Consider a vector $y$ that we define as
$$
y = e^{j\omega t}.
$$
By projecting our original signal $x(t)$ onto this vector $y$, we are intuitively getting all the "information" that is in the "direction" of this complex exponential.

More formally, the scalar projection of $x(t)$ in the direction of a complex exponential $e^{j\omega t}$ using our previous notation is
$$
proj_y(x(t)) = \frac{1}{||e^{j\omega t}||}\langle x(t), e^{j\omega t}\rangle = \frac{1}{||e^{j\omega t}||}\int_{-\infty}^\infty x(t) e^{-j\omega t} dt.
$$
If this final expression looks familiar, that's because this is precisely the equation for the Fourier transform, $F(\omega)$! If we replace $proj_y(x(t))$ with $X(\omega)$ and add a scaling factor such that our transform is unitary, we arrive at the familiar expression
$$
X(\omega) = \frac{1}{2\pi}\int_{-\infty}^\infty x(t) e^{-j\omega t} dt
$$


## Why do we use $e^{j\omega t}$ as the basis?
Consider an LTI system characterized by an impulse response $h(t)$. A curious property of LTI systems is that complex exponential inputs are eigenfunctions of the system. That is, if the system is defined as $\mathcal{S}\{x(t)\}$, then for input $x(t) = e^{j\omega t}$, 
$$
\mathcal{S}\{e^{j\omega t}\} = \int_{-\infty}^\infty e^{j\omega (t-\tau)} h(\tau) d\tau = \underbrace{e^{j\omega t}}_{x(t)}\underbrace{\int_{-\infty}^\infty e^{j\omega \tau} h(-\tau) d\tau}_{H(\omega)} = H(\omega) x(t)
$$

Furthermore, since all LTI systems are linear by definition, it follows that an input into a system which is a linear combination of scaled and shifted complex exponentials will have each term multiplied by the $H(\omega)$ from before. In particular,
$$
\mathcal{S}\left\{\frac{1}{2\pi} \int_{\mathbb{R}} X(\omega) e^{j\omega t} d\omega \right\} = \frac{1}{2\pi} \int_{\mathbb{R}} H(\omega)X(\omega) e^{j\omega t} d\omega
$$

The bottom line is this: If we can express our signal as a linear combination of scaled and shifted complex exponentials, then the output of the system will have a Fourier representation given by $H(\omega)X(\omega)$. 

[^1]: https://math.stackexchange.com/questions/2340094/why-frac12-pi-int-infty-inftyeiwt-xdw-is-the-dirac-delta-func 